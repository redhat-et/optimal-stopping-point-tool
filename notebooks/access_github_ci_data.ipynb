{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38a535-2bcd-46eb-8308-74dee0b62b4a",
   "metadata": {},
   "source": [
    "# Collect data for github action workflow runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7bfd4-0946-4237-93a7-897686ca6a4e",
   "metadata": {},
   "source": [
    "In this notebook, we collect historical test data like the test duration values from running workflows on Github using the GitHub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b929752-120c-4ac2-b71b-ee59783706df",
   "metadata": {},
   "source": [
    "## Collect data for selected workflow runs of a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb899-9f3c-4fe6-910f-792a41549a75",
   "metadata": {},
   "source": [
    "From historical test workflow runs, want to extract\n",
    "- time durations\n",
    "- workflow run status & conclusion\n",
    "\n",
    "We can get workflow IDs of the test that we are interested in from https://api.github.com/repos/{ORG}/{REPO}/actions/workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fb7a56-46e8-44c3-a6a0-b4bfe23fe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b754e6-e4ab-4fac-972c-d31289f178f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "TOKEN = os.getenv(\"GITHUB_ACCESS_TOKEN\")\n",
    "ORG = os.getenv(\"ORG\")\n",
    "REPO = os.getenv(\"REPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842fbe80-3d54-4dfb-83c3-c18c5cdcda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode can be \"check or \"workflow\" depending on whether you want to collect checks data or workflows data\n",
    "MODE = \"workflow\"\n",
    "test_id = \"28698040\" # Pre-commit test\n",
    "# test_id = \"29176617\" # Build and push image\n",
    "# test_id = \"37149896\" # File linting\n",
    "# test_id = \"37149895\" # Spell Check\n",
    "# test_id = \"39411153\" #\"Compile all queries using the latest stable CodeQL CLI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eb146-b77a-4f3e-be81-906a9cf92885",
   "metadata": {},
   "source": [
    "* Workflows: For example, lets collect data for the test ID 28698040 for the workflow runs in the repository `oss-aspen/8Knot` https://api.github.com/repos/oss-aspen/8Knot/actions/workflows\n",
    "\n",
    "* Checks: Get commits for a repo and get check runs for each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154cd635-e042-434b-9180-f9408e095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_numbers(test_id):\n",
    "    \"\"\"\n",
    "    Get the total count of tests.\n",
    "    Find the pages on github-actions.\n",
    "    \"\"\"\n",
    "    command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?\"\"\".format(TOKEN, ORG, REPO, test_id)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "    total_count = output['total_count']\n",
    "    page_numbers = int(total_count/30) # by default number of tests on one page is 30\n",
    "    return page_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b74535-4200-49a7-a589-b7adba1bbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow_runs(test_id, page_numbers):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    for p in range(1,page_numbers+1):\n",
    "        command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?page={}\"\"\".format(TOKEN, ORG, REPO, test_id, p)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        if p==1:\n",
    "            df = pd.json_normalize(output['workflow_runs'])\n",
    "        else:\n",
    "            df2 = pd.json_normalize(output['workflow_runs'])\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54ffd7-9dc3-4331-8f5c-62a3f419130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_check_runs(commits):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    appended_data = []\n",
    "    for commit in commits:\n",
    "        command = \"\"\"curl -L \\\n",
    "          -H \"Accept: application/vnd.github+json\" \\\n",
    "          -H \"Authorization: Bearer {}\"\\\n",
    "          -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "          https://api.github.com/repos/{}/{}/commits/{}/check-runs\"\"\".format(TOKEN, ORG, REPO, commit)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        appended_data.append(pd.json_normalize(output['check_runs']))\n",
    "\n",
    "    df = pd.concat(appended_data, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe31317-ea6b-450c-b818-b0e323d4a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits():\n",
    "    \"This function gets all commit refs for a github repo\"\n",
    "\n",
    "    command =  \"\"\"curl -L \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/commits\"\"\".format(TOKEN, ORG, REPO)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "\n",
    "    df = pd.json_normalize(output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b21b5a1-60fd-4fd5-9065-dc0bc128b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"check\":\n",
    "    # get checks\n",
    "    df_commits = get_commits()\n",
    "    commit_ids = list(df_commits['sha'])\n",
    "    checks_df = get_check_runs(commit_ids)\n",
    "    test_df = checks_df[['started_at', 'completed_at', 'id', 'status', 'conclusion', 'external_id', 'name']]\n",
    "    test_df = test_df.rename(columns={'external_id': 'test_id', 'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['completed_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['started_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "\n",
    "elif MODE == \"workflow\":\n",
    "    # get workflows\n",
    "    page_numbers = get_page_numbers(test_id)\n",
    "    workflow_df = get_workflow_runs(test_id, page_numbers)\n",
    "    test_df = workflow_df[['created_at', 'updated_at', 'id', 'status', 'conclusion']]\n",
    "    test_df = test_df.rename(columns={'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "    test_df['test_id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a3a9d1-d34c-49b1-ae7e-5498281af3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-21T16:47:52Z</td>\n",
       "      <td>2023-03-21T16:48:28Z</td>\n",
       "      <td>4481655529</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-02T18:04:52Z</td>\n",
       "      <td>2023-03-02T18:05:21Z</td>\n",
       "      <td>4316905413</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-28T22:46:09Z</td>\n",
       "      <td>2023-02-28T22:46:39Z</td>\n",
       "      <td>4298089675</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-28T22:42:47Z</td>\n",
       "      <td>2023-02-28T22:43:10Z</td>\n",
       "      <td>4298071211</td>\n",
       "      <td>completed</td>\n",
       "      <td>failure</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-28T22:21:25Z</td>\n",
       "      <td>2023-02-28T22:21:46Z</td>\n",
       "      <td>4297918764</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-22T23:15:44Z</td>\n",
       "      <td>2023-02-22T23:16:07Z</td>\n",
       "      <td>4247826657</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-22T18:27:33Z</td>\n",
       "      <td>2023-02-22T18:28:00Z</td>\n",
       "      <td>4245797712</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-22T17:58:00Z</td>\n",
       "      <td>2023-02-22T17:58:29Z</td>\n",
       "      <td>4245558935</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-02-22T14:42:04Z</td>\n",
       "      <td>2023-02-22T14:42:26Z</td>\n",
       "      <td>4243845186</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-21T21:03:50Z</td>\n",
       "      <td>2023-02-21T21:04:14Z</td>\n",
       "      <td>4236840889</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at            updated_at      run_id     status  \\\n",
       "0  2023-03-21T16:47:52Z  2023-03-21T16:48:28Z  4481655529  completed   \n",
       "1  2023-03-02T18:04:52Z  2023-03-02T18:05:21Z  4316905413  completed   \n",
       "2  2023-02-28T22:46:09Z  2023-02-28T22:46:39Z  4298089675  completed   \n",
       "3  2023-02-28T22:42:47Z  2023-02-28T22:43:10Z  4298071211  completed   \n",
       "4  2023-02-28T22:21:25Z  2023-02-28T22:21:46Z  4297918764  completed   \n",
       "5  2023-02-22T23:15:44Z  2023-02-22T23:16:07Z  4247826657  completed   \n",
       "6  2023-02-22T18:27:33Z  2023-02-22T18:28:00Z  4245797712  completed   \n",
       "7  2023-02-22T17:58:00Z  2023-02-22T17:58:29Z  4245558935  completed   \n",
       "8  2023-02-22T14:42:04Z  2023-02-22T14:42:26Z  4243845186  completed   \n",
       "9  2023-02-21T21:03:50Z  2023-02-21T21:04:14Z  4236840889  completed   \n",
       "\n",
       "  conclusion  run_duration   test_id  \n",
       "0    success          36.0  28698040  \n",
       "1    success          29.0  28698040  \n",
       "2    success          30.0  28698040  \n",
       "3    failure          23.0  28698040  \n",
       "4    success          21.0  28698040  \n",
       "5    success          23.0  28698040  \n",
       "6    success          27.0  28698040  \n",
       "7    success          29.0  28698040  \n",
       "8    success          22.0  28698040  \n",
       "9    success          24.0  28698040  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b190635-42b8-4011-a244-7dc951375f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392e9f16-92f5-4ef0-99af-0399765db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating passing and failing dfs which are neccesary for computing fit distributions\n",
    "passing_df = test_df[test_df['conclusion'] == 'success'] \n",
    "failures_df = test_df[test_df['conclusion'] == 'failure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9193e440-27a8-4c6f-8a24-23f07e6a2445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12038cd-03aa-44b6-aa8b-e94ec2184d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb5a164-1b39-4c73-b7e1-b324338c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "passing_train, passing_test = train_test_split(passing_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a29a24-0031-4b6b-9df9-a14d42eeb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "failing_train, failing_test = train_test_split(failures_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8249748-1e5e-4022-8e40-8c7860b943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ade87d-091f-4c5d-99c8-62b8490794ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d94578-0e8c-4ce0-8cb5-4b87c9da6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a375d6-6271-48db-a532-519665fad2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11973eff-ca6d-4749-bbfe-ebe17d3b3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_train.to_csv(\"../data/processed/{}passing_train.csv\".format(test_id))\n",
    "failing_train.to_csv(\"../data/processed/{}failing_train.csv\".format(test_id))\n",
    "passing_test.to_csv(\"../data/processed/{}passing_test.csv\".format(test_id))\n",
    "failing_test.to_csv(\"../data/processed/{}failing_test.csv\".format(test_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb1d9-abae-4ab9-b470-0f908ef66c57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we interact with the github api to collect the data for all workflow runs. In future work, we will look into using this data to perform statistical tests using OSP model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
